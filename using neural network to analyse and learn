import tensorflow as tf
import numpy as np
 
from create1_sentiment import create_feature_sets_and_labels 

train_x, test_x, classification_y1, classification_y2 = create_feature_sets_and_labels('pos.txt', 'neg.txt', test_size = 0.1)
 
n_hl1 = 500
n_hl2 = 500
n_hl3 = 500
classes = 2
batch_size = 100

x = tf.placeholder('float',[None, len(train_x[0])])#flattening in the input data set
y = tf.placeholder('float', [None, 2])

def neuralnet(data):
    #(input data*weight)+biases
    hl1 = {'weights':tf.Variable(tf.random_normal([len(train_x[0]), n_hl1 ])),
           'biases':tf.Variable(tf.random_normal([n_hl1]))}
    
    hl2 = {'weights':tf.Variable(tf.random_normal([n_hl1, n_hl2])),
           'biases':tf.Variable(tf.random_normal([n_hl2]))}
    
    hl3 = {'weights':tf.Variable(tf.random_normal([n_hl2, n_hl3])),
           'biases':tf.Variable(tf.random_normal([n_hl3]))}
                                
    output = {'weights':tf.Variable(tf.random_normal([n_hl3, classes])),
           'biases':tf.Variable(tf.random_normal([classes]))}
        
        #(input data*weight)+biases
    l1 = tf.add(tf.matmul(data, hl1['weights']), hl1['biases'])
    l1 = tf.nn.relu(l1)

    l2 = tf.add(tf.matmul(l1, hl2['weights']), hl2['biases'])
    l2 = tf.nn.relu(l2)

    l3 = tf.add(tf.matmul(l2, hl3['weights']), hl3['biases'])
    l3 = tf.nn.relu(l3)

    out = tf.add(tf.matmul(l3, output['weights']), output['biases'])
    return out

def train_neuralnet(x):
    prediction = neuralnet(x)

    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = prediction))
    optimizer = tf.train.AdamOptimizer().minimize(cost)

    hm_epochs = 10
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        for epoch in range(hm_epochs):
            epoch_loss = 0
            
            i = 0
            while i<len(train_x):
                start = i
                end = i+batch_size
                
                batch_x = np.array(train_x[start:end])
                batch_y = np.array(classification_y1[start:end])

                _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y} )
                epoch_loss += c
                i += batch_size

            print('Epoch',epoch,'completed out of',hm_epochs,'loss:',epoch_loss)
        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))
        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))
        print('Accuracy:', accuracy.eval({x:test_x, y:classification_y2}))

train_neuralnet(x)
